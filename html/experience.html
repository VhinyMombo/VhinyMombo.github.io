<head>
    <title>Dossier de Compétence</title>
    <meta charset="utf-8">
    <meta name="viewport"
            content="width=device-width, initial-scale=1, user-scalable=yes">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="../style.css">
  </head>
  
  <body>
      <div class="cv-container">
        <div class="left-column">
          
        </div> 
  
        <div class="right-column">
          <div class="header">
            <h1>Vhiny-Guilley <span class="text-blue text-uppercase">MOMBO</span></h1>
            <p><strong><span class="text-blue"> Ingénieur Data Scientist / Machiine Learning Engineer</span></strong></p>
            <ul class="infos">
              <li><i class="icon fas fa-at text-blue"></i> <a href="mailto:vmombo78@gmail.com">vmombo78@gmail.com</a></li>
              <li><i class="icon fas fa-phone text-blue"></i> 07 53 41 49 53</li>
              <li><i class="icon fas fa-map-marker-alt text-blue"></i> 5 Clos de La Cathédrale 6212, Evry, 91000</li>
              <li><i class="icon fab fa-linkedin text-darkblue"></i> <a href="https://www.linkedin.com/in/vhinyguilley-mombo/">Vhiny-Guilley Mombo</a></li>
            </ul>
            <br><br>
            Autonome, Flexible, Curieux, Esprit d'équipe, Proactif.
        
        </div>

        <div class="content">

            
            <div class="right-column-3">
              <strong><a href="comp.html"><strong><i class="fas fa-long-arrow-alt-left"></i></strong> Formation et Compétences </a></strong>
            </div>

            <div class="section">
                <h2>Expériences <span class="text-blue">professionnelles</span></h2>
                
                <p>
                  <strong>Nov 2022 <i class="fas fa-long-arrow-alt-right"></i> Present</strong>
                  <br>
                  <strong><span class="text-blue"> Data Science/Applied Scientist </span></strong> at <em>Finres</em>
                  <br><br><em>Contexte : Exerçant dans le domaine de l'analyse financière, ma mission consiste à élaborer des modèles prédictifs de pointe et à effectuer des analyses statistiques approfondie pour aider a la prise de décisions stratégiques et guider les orientations politiques en réponse aux changements climatiques.</em>
                  <ul class="experience-list">
                    <li>Conception et mise en œuvre de modèles prédictifs utilisant des techniques d'apprentissage automatique et d'apprentissage profond pour prévoir le rendement futur des cultures.</li>
                    <li>Développement d'un index de suitabilité climatique pour le secteur agricole afin d'optimiser la prise de décisions et evaluer le risk que fait face certaines cultures dans le monde.</li>
                    <li>Collaboration avec les départements financiers et informatiques pour intégrer les modèles dans les processus commerciaux et garantir l'exactitude et l'accessibilité des données.</li>
                    <li>Développement d'un agent LLM pour interroger la base de données de documents internes et construire des rapports automatiques pour une utilisation interne et externe, améliorant ainsi la prise de décisions basée sur les données.</li>
                    <li>Amélioration continue des techniques de modélisation, en restant à la pointe des dernières avancées en technologies d'IA et d'apprentissage automatique.</li>
                  </ul>
                  
                  <br>
                  <em>Technologies Utilisées</em> : <strong>Python, R, TensorFlow, PyTorch, AWS EC2, AWS S3, Langchain, ChromaDB</strong>
                  <br>
                  <br>
                  <em>Notions Utilisées</em> : <strong>Machine Learning, Risk Management, Computer Vision, Financial Analysis, Statistiques</strong>
                
                </p>
    
              </div>
                
              <div class="section">
                <p>
                  <strong>2021 <i class="fas fa-long-arrow-alt-right"></i> 2022</strong>
                  <br>
                  <strong><span class="text-blue"> Data Scientist / Data Engineer </span></strong> Apprenti chez <em>SESAN</em>
                  <br> <br> <em> Contexte : Suite au développement d'une application de coordination qui induit une grande quantité de données, mon but, au sein d’une équipe de data scientists, était de créer un nouvel entrepôt de données structurées (Data Mart ), à partir de la data warehouse de l’entreprise, pour faciliter la construction des KPI de ladite application, puis de créer un algorithme de Machine Learning pour faire de la segmentation </em>
    
                </p>
                  <ul class="experience-list">
                    <li>Création d'un data mart à partir d'un data warehouse via une intégration ETL pour faciliter l'accès et le traitement de données.</li>
                    <li>Recueil du besoin utilisateur , enrichissement des données et création de tables thématiques résumant des informations particulières sur l’application.</li>
                    <li>Documentation du nouvel entrepôt et réalisation d'un modèle relationnel de données interactif de type Neo4j.</li>
                    <li>La maintenance et le développement de la V2 d’une application web de restitution d’indicateurs de suivi et d'utilisation de l'application de coordination.</li>
                    <li>Analyse descriptive de données et élaboration d'un algorithme de segmentation des patients.
                      <ul class="experience-list2">
                        <li>Création d'un algorithme de Machine Learning pour la segmentation des patients basé sur des symptômes COVID et leur facteur de risques, en s'inspirant sur la segmentation client en assurance.</li>
                        <li>Mise en place d'une API pour rendre démocratiser le modèle au sein de l'équipe.</li>
                      </ul>
                    </li>
                  </ul>
                  <br>
                  <em>Technologies Utilisées</em> : <strong>R , Spark,  Apache Airflow,  Git,  Gitlab CI/CD,  Apache Kafka,  Shiny,  JavaScript,  SQL,  Oracle,  D3,  HTML,  CSS,  CronR,  Scikit-learn,  Reticulate.</strong>
                  <br>
                  <br>
                  <em>Notions Utilisées</em> : <strong>Analyse de Données, Gestion de Base de donnée, Data Engineering, Machine Learning.</strong>
    
              </div>
    
              <div class="section">
                <p>
                  <strong>06/2021 <i class="fas fa-long-arrow-alt-right"></i> 08/2021</strong>
                  <br>
                  <strong><span class="text-blue"> Data Analyst </span></strong>  Stagiaire chez <em> Le CNAM</em>
                  <br> <br> <em> Contexte : Grâce à la disponibilité des données de régularité et des activités de la SNCF,  mon but était de construire un outil de reporting et une bibliothèque Python pour l'analyse de données pour le département de Mathématiques du CNAM. </em>
                </p>
                <ul class="experience-list">
                  <li>Collection à partir des APIs SNCF et Automatisation de processus de récupération des données.</li>
                  <li>Traitement de données de type série temporelle et réalisation des tests d'hypothèses statistiques sur les lois suivies par les données de régularités des trains ou d'affluence en gare.</li>
                  <li>Estimation des lois suivies par ces données à partir des maximums de vraisemblances. Prédictions des régularité et affluence en gare avenir.</li>
                  <li>Construction d'un module python, contenant toutes les fonctions d'estimation des paramètres de lois statistiques utilisées.</li>
                  <li>Construction d'une IHM de type dashboard pour la visualisation des données extraites et des résultats d'analyse réalisés en back-end. Puis déploiement via Heroku.</li>
                </ul>
                <br>
                  <em>Technologies Utilisées</em> : <strong>Python, Dash,  Scikit-Learn,  Numpy,  Pandas,  Scipy,  HTML,  CSS,  WSGI,  Gunicorn,  Plotly,  Git,  Heroku CI/CD </strong>
                  <br>
                  <br>
                  <em>Notions Utilisées</em> : <strong>Analyse de données, Statistiques, Modélisation des séries temporelles, Développement Web.</strong>
              </div>
    
              <div class="section">
                <p>
                  <strong>02/2020 <i class="fas fa-long-arrow-alt-right"></i> 08/2020</strong>
                  <br>
                  <strong><span class="text-blue"> Ingénieur R&D </span></strong>  Stagiaire chez <em> Petroleum Geo - Services </em>
                  <br> <br> <em> Contexte : u sein du service traitement d'images, j'ai travaillé en tant stagiaire chercheur pour l'élaboration d'un algorithme de traitement d'image pour améliorer l'algorithme dit  << Migration au sens de moindres carrées >> . La migration étant un problème d'optimisation convexe.</em>
                </p>
                <ul class="experience-list">
                  <li>CMise en place d'un algorithme migration plus robuste qui améliore la qualité des images issues du pipeline des données.</li>
                  <li>TÉtude de l’état de l’art sur ce problème d’optimisation</li>
                  <li>Analyse des résultats issus de l'algorithme utilisé dans l'entreprise.</li>
                  <li>CAmélioration de la solution existante, en changeant l'algorithme d'optimisation par une descente de gradient conjuguées. Ceci améliorant la convergence de l'algorithme et la complexité temporelle.</li>
                  <li>Comparaison des résultats sur données synthétiques et test  de l’algorithme sur données réelles.</li>
                </ul>
                <br>
                  <em>Technologies Utilisées</em> : <strong>C++,  Python, Matlab, Git,  Bash,  Scipy,  Scikit-Learn,  PIL,  Matplotlib </strong>
                  <br>
                  <br>
                  <em>Notions Utilisées</em> : <strong>Optimisation Convexe, Traitement d’Image, Traitement du Signal, Recherche Opérationnelle.</strong>
              </div>
    
    
              <div class="section">
                <p>
                  <strong>02/2020 <i class="fas fa-long-arrow-alt-right"></i> 08/2020</strong>
                  <br>
                  <strong><span class="text-blue"> Data Analyst </span></strong>  Stagiaire chez <em> CGG </em>
                  <br> <br> <em> Contexte : Au sein  d'une équipe de traitements de données composées de 7, mon rôle était de veiller à la qualité des données issues d'une étape du pipeline de traitement. utilisé par l'équipe. /em>
                </p>
                <ul class="experience-list">
                  <li>Extraction et normalisation des données. Contrôle qualité des données issus du pipeline de traitement.</li>
                  <li>Amélioration d'une des fonctions de transformation du pipeline en intégrant de nouvelle données au pendant l'entraînement du modèle sur lequel repose la fonction.</li>
                  <li>Réalisation de reporting et présentation hebdomadaire des résultats auprès du client. Puis transformation du besoin du client en problème data.</li>
                </ul>
                <br>
                  <em>Technologies Utilisées</em> : <strong>Python,  NoSQL,  Scipy,  Bash,  PIL,  Matplotlib, Shell</strong>
                  <br>
                  <br>
                  <em>Notions Utilisées</em> : <strong>Analyse de Données, Traitement d’Images</strong>
              </div>
    
              <div class="section">
                <h2> <span class="text-blue">Projets</span></h2>
                
                <p>
                  <br>
                  <strong><span class="text-blue"> Détection de Fraude Bancaire : 3 mois en 2021 </span></strong>
                  <br> <br> <em> Contexte : Mise en application des cours de Machine Learning en resolvant un problème sous forme de compétition Kaggle </em>
    
                </p>
                  <ul class="experience-list">
                    <li>Nettoyage et Analyse de données </li>
                    <li> Développement d’un modèle de classification qui discrimine les transactions bancaires frauduleuses des non frauduleuses</li>
                    <li>Apprentissage et Evaluation du modèle</li>
                    <li>Mise en production du modèle</li>
                  </ul>
                  <br>
                  <em>Technologies Utilisées</em> : <strong>Python, Scikit-Learn , Numpy, Pandas, Seaborn, Keras, Dash,  HTML/CSS, Heroku, Git </strong>
                  <br>
                  <em>Notions Utilisées</em> : <strong>Analyse de données,  Machine Learning, Apprentissage Supervisée, SVM, Naives Bayes, Random Forest </strong>
    
              <div class="section">
                <p>
                  <br>
                  <strong><span class="text-blue"> Prédiction de la demande de vélo urbain : 1 mois en 2021 </span></strong>
                  <br> <br> <em> Contexte : Dans une équipe à 4 un jeu de données nous a été fourni pour faire une étude statistiques sur la demande de vélo à Séoul.</em>
    
                </p>
                  <ul class="experience-list">
                    <li>Analyse de données et Normalisation du dataset</li>
                    <li> Utilisation d'algorithme de ML pour prédire la demande de vélos en libre-service en utilisant les données d'utilisation saisonnière, la météo et le comportement des usagers. </li>
                  </ul>
                  <br>
                  <em>Technologies Utilisées</em> : <strong>Python, Scikit-Learn, Numpy, Pandas, Keras, SMOTE, Plotly </strong>
                  <br>
                  <em>Notions Utilisées</em> : <strong>  Machine Learning, Analyse Multivariée, Data Visualisation </strong>
    
              </div>
    
               <div class="section">
                <p>
                  <br>
                  <strong><span class="text-blue"> Création du web app pour l'aide au paris sportif : 3 mois en 2022 </span></strong>
                  <br> <br> <em> Contexte : Dans le cadre d'un projet personnel, j'avais pour mission de créer une plateforme qui aide les parieurs à mieux allouer le montants de paris</em>
    
                </p>
                  <ul class="experience-list">
                    <li> Modèlisation du système de paris en a doptant une approche probabiliste à 2 ou 3 issus</li>
                    <li> Definition de stratégie d'investissement en utilisant la théorie de portefeuille de Markowitz</li>
                    <li>Création d'une librarie python pour l'aide à l'allocation de fonds pour un paris sportifs</li>
                    <li>Création d'une API pour utliser la librarie et réaliser des test unitaires sur le modèle utilisée </li>
                  </ul>
                  <br>
                  <em>Technologies Utilisées</em> : <strong>Python, Streamlit, Numpy, Pandas, Plotly, HTML/CSS </strong>
                  <br>
                  <em>Notions Utilisées</em> : <strong>  Probabilité, Optimisation, Data Visualisation, developpement web </strong>
    
              </div>
    
              <div class="section">
                <p>
                  <br>
                  <strong><span class="text-blue"> Reconnaissance de langages écrits:  2  mois en 2022</span></strong>
                  <br> <br> <em> Contexte : Dans le cadre du cours d'Apprentissage Non-Supervisée, on a implementé un algorithme pour discrimer les textes en Français de ceux en anglais</em>
    
                </p>
                  <ul class="experience-list">
                    <li> Implémentation d'un algorithme de Viterbi qui prend en entrée un texte, et retourne la langue dans laquelle ce dernier est écrit, en utilisant des approches probabilistes telles que Naïves Bayes et des chaînes de Markov</li>
                  <li>Implémentation d'un algorithme de Baum-Welch qui permet de distinguer des séquences dans un texte avec des séquences en anglais et en français </li>
                  </ul>
                  <br>
                  <em>Technologies Utilisées</em> : <strong>Python, Streamlit, Numpy, Pandas, Plotly, HTML/CSS </strong>
                  <br>
                  <em>Notions Utilisées</em> : <strong>  Probabilité, Chaine de Markov Caché, Modèle à Bloc Stochastique </strong>
    
              </div>
    
    
            <div class="section">
              <h2>Centres d'<span class="text-blue">intérêt</span></h2>
              <p>
                <ul class="infos">
                Piano et Instruments à cordes
                <br>
                Enigmes Mathématiques
                <br>
                Lecture 
                <br>
                Calisthenics
                <br>
                Jeux de dames
                <br>
                Informatiques
                </ul>
              </p>
            </div>
    
    
              <div class="section">
                <h2>CERTIFICATIONS <span class="text-blue"></span></h2>
    
                <ul>
                  <li> <strong>Big Data Hadoop and Spark with Scala</strong> – Udemy (43 h)</li>
                  <li><strong>Microsoft Azure Machine Learning for Data Scientist</strong>  – Coursera ( 15 h) </li>
                  <li><strong>Machine Learning Engineering for Production (MLOps)</strong> – Coursera (50 h)</li>
                  <li><strong>Financial Markets</strong> – Coursera (40 h)</li>
                  
    
                </ul>
                  
    
                  
                  <br>
    
              </div>



        </div>
    </div>
</body>

