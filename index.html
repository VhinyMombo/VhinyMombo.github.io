<head>
  <title>Dossier de Compétence</title>
  <meta charset="utf-8">
  <meta name="viewport"
          content="width=device-width, initial-scale=1, user-scalable=no">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
    <div class="cv-container">
      <div class="left-column">
        <!--<div class="section">
          <p>
            <i class="icon fab fa-linkedin text-darkblue"></i> pierre-gomba
          </p> 
        </div>
        <div class="section">
          <h2>À PROPOS</h2>
          <p>
            Le <strong>Front-end</strong> est une de mes passions : j’aime intégrer ou imaginer des interfaces modernes, les rendre responsive et les dynamiser avec des animations élégantes. Mes deux technos de coeur sont <strong>Angular</strong> et <strong>Bootstrap</strong>, que j’utilise depuis plus de 6 ans. Je suis aussi Fullstack : PHP, MySQL, Doctrine… 
          </p>
          <p>
            De nature débrouillard et indépendant dans mon travail, j’aime apprendre de nouvelles technologies, passer du temps à résoudre des problèmes et réaliser du code de qualité. Mes valeurs de travail : clean code, flexibilité, performance et sérieux.
          </p>
        </div>
        <div class="section">
          <h2>COMPÉTENCES</h2>
          <ul class="skills">
            <li><i class="icon fas fa-check-circle text-darkblue"></i> <strong>Angular &#124; Typescript</strong></li>
            <li><i class="icon fas fa-check-circle text-darkblue"></i> <strong>Bootstrap</strong></li>
            <li><i class="icon fas fa-check-circle text-darkblue"></i> <strong>HTML5 &#124; CSS3 &#124; SASS</strong></li>
            <li><i class="icon fas fa-check-circle text-darkblue"></i> <strong>Javascript</strong></li>
            <li><i class="icon fas fa-check-circle text-darkblue"></i> <strong>jQuery</strong></li>
            <li><i class="icon fas fa-check-circle text-darkblue"></i> <strong>npm &#124; Webpack</strong></li>
            <li><i class="icon fas fa-check-circle text-darkblue"></i> PHP</li>
            <li><i class="icon fas fa-check-circle text-darkblue"></i> Zend Framework</li>
            <li><i class="icon fas fa-check-circle text-darkblue"></i> MySQL</li>
            <li><i class="icon fas fa-check-circle text-darkblue"></i> Git &#124; Github</li>
          </ul>
        </div>
        <div class="section">
          <h2>Langues</h2>
          <p>
            Français, langue maternelle
            <br>
            Anglais, compétence professionnelle
          </p>
        </div>
        <div class="section">
          <h2>Centres d'intérêt</h2>
          <p>
            Jeux vidéo, jouer et développer
            <br>
            Musique, écoute et composition
            <br>
            Art en général
            <br>
            Sport
            <br>
            Informatique en général
          </p>
        </div> -->
      </div> 

      <div class="right-column">
        <div class="header">
          <h1>Vhiny-Guilley <span class="text-blue text-uppercase">MOMBO</span></h1>
          <p><strong><span class="text-blue"> Ingénieur Data Scientist / Data Engineer</span></strong></p>
          <ul class="infos">
            <li><i class="icon fas fa-at text-blue"></i> <a href="mailto:vmombo78@gmail.com">vmombo78@gmail.com</a></li>
            <li><i class="icon fas fa-phone text-blue"></i> 07 53 41 49 53</li>
            <li><i class="icon fas fa-map-marker-alt text-blue"></i> 5 Clos de La Cathédrale 6212, Evry, 91000</li>
            <li><i class="icon fab fa-linkedin text-darkblue"></i> <a href="https://www.linkedin.com/in/vhinyguilley-mombo/">Vhiny-Guilley Mombo</a></li>
          </ul>
          <br><br>
          Autonome, Flexible, Curieux, Esprit d'équipe, Proactif.
        </div>



        <div class="content">
          <!--
          <div class="row">
            <div class="col-md-6">
            <h2><span class="text-blue"> Savoir-Être </span></h2>
            </div>
            <div class="col-md-6">
            <h2><span class="text-blue"> Savoir-Faire</span></h2>
            </div>

          </div>
          -->

          <div class="section">
            <h2>PROJET<span class="text-blue"> PROFESSIONNEL </span></h2>

            Dès le début de mes études supérieures, je me suis passionné pour les technologies
            informatiques. Guidé par ma curiosité et ma soif d’apprendre de nouvelles choses, je me suis
            dirigé vers le domaine de la data science.
            <br><br>
            Mon objectif actuel est de pouvoir vous accompagner et vos clients dans leurs projets
            d’analyse de données et de mise en place d’algorithmes de machine learning.
            
            <br><br>

            Ingénieur en Mathématiques Appliquées et Titulaire d'un M2 en Data Science, je
            m’intéresse fortement à la data science et au data engineering. Mon bagage informatique et mathématique m’a
            permis d’aborder ces derniers sans difficultés. J’ai pu me former concrètement sur différents
            aspects du domaine comme l'integration ETL des données, le traitement préalable d’un jeu de données, l’apprentissage
            supervisé et non supervisé ou encore la data-visualisation. À cela s’ajoute des expériences
            professionnelles et académiques directement en phase avec le métier.
            <br><br>
            Mon ambition à court terme est
            de mûrir professionnellement en explorant divers aspects du domaine, pour ensuite prendre
            plus de responsabilités à moyen terme.
            Vous l’aurez compris, l'envoi de ce lien pour échanger sur votre besoin est tout sauf un
            hasard.


           </div> 
          <div class="section">
            <h2><span class="text-blue"> FORMATIONS </span></h2>
            
            <p>
              <strong>2021 <i class="fas fa-long-arrow-alt-right"></i> 2022</strong>
              <br>
              <em> <strong>M2 Data Science </strong> en double diplôme </em>, Diplômé, Université Paris Saclay
              <br>
              <em>Cours suivis</em> :
              Statistiques Asymptotiques, Optimisation Convexe, Deep Learning, Machine Learning, Système de Gestion de Base de Données, Modèle graphique, Computer Vision, GPU & Algorithmiques,  Unsupervised Learning, Machine Learning pour la finance.
            </p>

            <p>
              <strong>2020 <i class="fas fa-long-arrow-alt-right"></i> 2022</strong>
              <br>
              <em> <strong>Ingénieur Mathématiques Appliquées et Informatiques </strong> </em>, Diplômé, ENSIIE
              <br>
              <em>Cours suivis</em> : 
              Modélisation Statistiques, NLP, Machine Learning, Pattern Recognition, Big Data, Analyse de données, Calcul Stochastique pour la Finance, Instruments et Modèles Financiers, BlockChain, Méthode de Simulation et Times Series, Gestion de Projet, Econometrie, Recherche Opérationnelle, Programmation Web, Pricing des options, Méthodes Numériques de Pricing,  IT Quant, Poisson Process for Insurance, Chaine de Markov.
            </p>

            <p>
              <strong>2017 <i class="fas fa-long-arrow-alt-right"></i> 2020</strong>
              <br>
              <em><strong>Ingénieur Traitement du Signal </strong> </em>, Diplômé, EOST Université de Strasbourg
              <br>
              <em>Cours Suivis : </em>
              Mathématiques, Traitement du Signal, Geo-Statistique, Problème Inverse, Analyse de données, Système d'Information Géographique, Traitement d'Image, Physiques, Analyse Numérique.
            </p>

            <p>
              <strong>2015 <i class="fas fa-long-arrow-alt-right"></i> 2017</strong>
              <br>
              <em>Classe Préparatoire au Grandes Écoles <strong>MPSI/MP</strong> </em>, Lycée Nationale Léon MBA
            </p>
          </div>
          
          <div class="section">
            <h2>COMPÉTENCES<span class="text-blue"> TECHNIQUES</span></h2>
              <strong>Machine Learning</strong> :    Keras, Scikit-Learn, Pandas, Numpy, NLTK, Caret
              <br>
              <strong>Data Visualization</strong> : Tableau, seaborn, ggplot2, matplotlib, Dash, Shiny, Plotly
              <br>
              <strong>Data Engineering</strong> : SQL, postgreSQL, NoSQL, Neo4j, Cypher, Spark, Hadoop, Airflow, kafka, Hive, HDFS, MapReduce.
              <br>
              <strong>Deep Learning</strong> : Tensorflow, Pytorch, NLP, Computer Vision, Transformers, BERT
              <br>
              <strong>Programmation</strong> : Python, R, MATLAB, C/C++, Java, scala, VBA, HTML/CSS, JavaScript
              <br>
              <strong>Plateforme Cloud</strong> : AzureML, AWS EC2, Dataiku
              <br>
              <strong>Autres</strong> : Git, Gitlab CI/CD, Flask, FastAPI, Streamlit, SQLAlchemy, Linux, Django
          </div>

          <div>
            <h2> SAVOIR<span class="text-blue">-FAIRE</span>
            </h2>
            <p>
            Analyse de données, Statistiques, Machine Learning, Deep Learning, Recherche Opérationnelle, Data Mining, Modélisation Statistiques, NLP, Traitement d’Image, Gestion de base de données, Developpement Python Modélisation statistique, Pricing Monte Carlo 
            </p>

          </div>
          
          <div class="section">
            <h2>Expériences <span class="text-blue">professionelles</span></h2>
            
            <p>
              <strong>2021 <i class="fas fa-long-arrow-alt-right"></i> 2022</strong>
              <br>
              <strong><span class="text-blue"> Data Scientist / Data Engineer </span></strong> Apprenti chez <em>SESAN</em>
              <br> <br> <em> Contexte : Suite au développement d'une application de coordination qui induit une grande quantité de données, mon but, au sein d’une équipe de data scientists, était de créer un nouvel entrepôt de données structurées (Data Mart ), à partir de la data warehouse de l’entreprise, pour faciliter la construction des KPI de ladite application, puis de créer un algorithme de Machine Learning pour faire de la segmentation </em>

            </p>
              <ul class="experience-list">
                <li>Création d'un data mart à partir d'un data warehouse via une intégration ETL pour faciliter l'accès et le traitement de données.</li>
                <li>Recueil du besoin utilisateur , enrichissement des données et création de tables thématiques résumant des informations particulières sur l’application.</li>
                <li>Documentation du nouvel entrepôt et réalisation d'un modèle relationnel de données interactif de type Neo4j.</li>
                <li>La maintenance et le développement de la V2 d’une application web de restitution d’indicateurs de suivi et d'utilisation de l'application de coordination.</li>
                <li>Analyse descriptive de données et élaboration d'un algorithme de segmentation des patients.
                  <ul class="experience-list2">
                    <li>Création d'un algorithme de Machine Learning pour la segmentation des patients basé sur des symptômes COVID et leur facteur de risques, en s'inspirant sur la segmentation client en assurance.</li>
                    <li>Mise en place d'une API pour rendre démocratiser le modèle au sein de l'équipe.</li>
                  </ul>
                </li>
              </ul>
              <br>
              <em>Technologies Utilisées</em> : <strong>R , Spark,  Apache Airflow,  Git,  Gitlab CI/CD,  Apache Kafka,  Shiny,  JavaScript,  SQL,  Oracle,  D3,  HTML,  CSS,  CronR,  Scikit-learn,  Reticulate.</strong>
              <br>
              <br>
              <em>Notions Utilisées</em> : <strong>Analyse de Données, Gestion de Base de donnée, Data Engineering, Machine Learning.</strong>

          </div>
          <div class="section">
            <p>
              <strong>06/2021 <i class="fas fa-long-arrow-alt-right"></i> 08/2021</strong>
              <br>
              <strong><span class="text-blue"> Data Analyst </span></strong>  Stagiaire chez <em> Le CNAM</em>
              <br> <br> <em> Contexte : Grâce à la disponibilité des données de régularité et des activités de la SNCF,  mon but était de construire un outil de reporting et une bibliothèque Python pour l'analyse de données pour le département de Mathématiques du CNAM. </em>
            </p>
            <ul class="experience-list">
              <li>Collection à partir des APIs SNCF et Automatisation de processus de récupération des données.</li>
              <li>Traitement de données de type série temporelle et réalisation des tests d'hypothèses statistiques sur les lois suivies par les données de régularités des trains ou d'affluence en gare.</li>
              <li>Estimation des lois suivies par ces données à partir des maximums de vraisemblances. Prédictions des régularité et affluence en gare avenir.</li>
              <li>Construction d'un module python, contenant toutes les fonctions d'estimation des paramètres de lois statistiques utilisées.</li>
              <li>Construction d'une IHM de type dashboard pour la visualisation des données extraites et des résultats d'analyse réalisés en back-end. Puis déploiement via Heroku.</li>
            </ul>
            <br>
              <em>Technologies Utilisées</em> : <strong>Python, Dash,  Scikit-Learn,  Numpy,  Pandas,  Scipy,  HTML,  CSS,  WSGI,  Gunicorn,  Plotly,  Git,  Heroku CI/CD </strong>
              <br>
              <br>
              <em>Notions Utilisées</em> : <strong>Analyse de données, Statistiques, Modélisation des séries temporelles, Développement Web.</strong>
          </div>

          <div class="section">
            <p>
              <strong>02/2020 <i class="fas fa-long-arrow-alt-right"></i> 08/2020</strong>
              <br>
              <strong><span class="text-blue"> Ingénieur R&D </span></strong>  Stagiaire chez <em> Petroleum Geo - Services </em>
              <br> <br> <em> Contexte : u sein du service traitement d'images, j'ai travaillé en tant stagiaire chercheur pour l'élaboration d'un algorithme de traitement d'image pour améliorer l'algorithme dit  << Migration au sens de moindres carrées >> . La migration étant un problème d'optimisation convexe.</em>
            </p>
            <ul class="experience-list">
              <li>CMise en place d'un algorithme migration plus robuste qui améliore la qualité des images issues du pipeline des données.</li>
              <li>TÉtude de l’état de l’art sur ce problème d’optimisation</li>
              <li>Analyse des résultats issus de l'algorithme utilisé dans l'entreprise.</li>
              <li>CAmélioration de la solution existante, en changeant l'algorithme d'optimisation par une descente de gradient conjuguées. Ceci améliorant la convergence de l'algorithme et la complexité temporelle.</li>
              <li>Comparaison des résultats sur données synthétiques et test  de l’algorithme sur données réelles.</li>
            </ul>
            <br>
              <em>Technologies Utilisées</em> : <strong>C++,  Python, Matlab, Git,  Bash,  Scipy,  Scikit-Learn,  PIL,  Matplotlib </strong>
              <br>
              <br>
              <em>Notions Utilisées</em> : <strong>Optimisation Convexe, Traitement d’Image, Traitement du Signal, Recherche Opérationnelle.</strong>
          </div>

          <div class="section">
            <p>
              <strong>02/2020 <i class="fas fa-long-arrow-alt-right"></i> 08/2020</strong>
              <br>
              <strong><span class="text-blue"> Data Analyst </span></strong>  Stagiaire chez <em> CGG </em>
              <br> <br> <em> Contexte : Au sein  d'une équipe de traitements de données composées de 7, mon rôle était de veiller à la qualité des données issues d'une étape du pipeline de traitement. utilisé par l'équipe. /em>
            </p>
            <ul class="experience-list">
              <li>Extraction et normalisation des données. Contrôle qualité des données issus du pipeline de traitement.</li>
              <li>Amélioration d'une des fonctions de transformation du pipeline en intégrant de nouvelle données au pendant l'entraînement du modèle sur lequel repose la fonction.</li>
              <li>Réalisation de reporting et présentation hebdomadaire des résultats auprès du client. Puis transformation du besoin du client en problème data.</li>
            </ul>
            <br>
              <em>Technologies Utilisées</em> : <strong>Python,  NoSQL,  Scipy,  Bash,  PIL,  Matplotlib, Shell</strong>
              <br>
              <br>
              <em>Notions Utilisées</em> : <strong>Analyse de Données, Traitement d’Images</strong>
          </div>

          <div class="section">
            <h2>Projets  <span class="text-blue">Etudiants</span></h2>
            
            <p>
              <br>
              <strong><span class="text-blue"> Détection de Fraude Bancaire : 3 mois en 2021 </span></strong>
              <br> <br> <em> Contexte : Mise en application des cours de Machine Learning en resolvant un problème sous forme de compétition Kaggle </em>

            </p>
              <ul class="experience-list">
                <li>Nettoyage et Analyse de données </li>
                <li> Développement d’un modèle de classification qui discrimine les transactions bancaires frauduleuses des non frauduleuses</li>
                <li>Apprentissage et Evaluation du modèle</li>
                <li>Mise en production du modèle</li>
              </ul>
              <br>
              <em>Technologies Utilisées</em> : <strong>Python, Scikit-Learn , Numpy, Pandas, Seaborn, Keras, Dash,  HTML/CSS, Heroku, Git </strong>
              <br>
              <em>Notions Utilisées</em> : <strong>Analyse de données,  Machine Learning, Apprentissage Supervisée, SVM, Naives Bayes, Random Forest </strong>

          <div class="section">
            <p>
              <br>
              <strong><span class="text-blue"> Prédiction de la demande de vélo urbain : 1 mois en 2021 </span></strong>
              <br> <br> <em> Contexte : Dans une équipe à 4 un jeu de données nous a été fourni pour faire une étude statistiques sur la demande de vélo à Séoul.</em>

            </p>
              <ul class="experience-list">
                <li>Analyse de données et Normalisation du dataset</li>
                <li> Utilisation d'algorithme de ML pour prédire la demande de vélos en libre-service en utilisant les données d'utilisation saisonnière, la météo et le comportement des usagers. </li>
              </ul>
              <br>
              <em>Technologies Utilisées</em> : <strong>Python, Scikit-Learn, Numpy, Pandas, Keras, SMOTE, Plotly </strong>
              <br>
              <em>Notions Utilisées</em> : <strong>  Machine Learning, Analyse Multivariée, Data Visualisation </strong>

          </div>

           <div class="section">
            <p>
              <br>
              <strong><span class="text-blue"> Création du web app pour l'aide au paris sportif : 3 mois en 2022 </span></strong>
              <br> <br> <em> Contexte : Dans le cadre d'un projet personnel, j'avais pour mission de créer une plateforme qui aide les parieurs à mieux allouer le montants de paris</em>

            </p>
              <ul class="experience-list">
                <li> Modèlisation du système de paris en a doptant une approche probabiliste à 2 ou 3 issus</li>
                <li> Definition de stratégie d'investissement en utilisant la théorie de portefeuille de Markowitz</li>
                <li>Création d'une librarie python pour l'aide à l'allocation de fonds pour un paris sportifs</li>
                <li>Création d'une API pour utliser la librarie et réaliser des test unitaires sur le modèle utilisée </li>
              </ul>
              <br>
              <em>Technologies Utilisées</em> : <strong>Python, Streamlit, Numpy, Pandas, Plotly, HTML/CSS </strong>
              <br>
              <em>Notions Utilisées</em> : <strong>  Probabilité, Optimisation, Data Visualisation, developpement web </strong>

          </div>

          <div class="section">
            <p>
              <br>
              <strong><span class="text-blue"> Reconnaissance de langages écrits:  2  mois en 2022</span></strong>
              <br> <br> <em> Contexte : Dans le cadre du cours d'Apprentissage Non-Supervisée, on a implementé un algorithme pour discrimer les textes en Français de ceux en anglais</em>

            </p>
              <ul class="experience-list">
                <li> Implémentation d'un algorithme de Viterbi qui prend en entrée un texte, et retourne la langue dans laquelle ce dernier est écrit, en utilisant des approches probabilistes telles que Naïves Bayes et des chaînes de Markov</li>
              <li>Implémentation d'un algorithme de Baum-Welch qui permet de distinguer des séquences dans un texte avec des séquences en anglais et en français </li>
              </ul>
              <br>
              <em>Technologies Utilisées</em> : <strong>Python, Streamlit, Numpy, Pandas, Plotly, HTML/CSS </strong>
              <br>
              <em>Notions Utilisées</em> : <strong>  Probabilité, Chaine de Markov Caché, Modèle à Bloc Stochastique </strong>

          </div>

          

        </div>
      </div>
    </div>
</body>